## ğŸ‘‰ Web Crawler ## 

# Libraries
import os
import re 
import time
import socket
import argparse
import urllib.request
from PIL import Image
from tqdm import tqdm
from pygame import mixer
from datetime import date

from urllib.request import urlretrieve
from urllib.error import HTTPError, URLError
from concurrent.futures import ThreadPoolExecutor

from selenium import webdriver
from selenium.common.exceptions import (
    ElementClickInterceptedException,
    NoSuchElementException,
    ElementNotInteractableException,)
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.action_chains import ActionChains



def parse_args():
    parser = argparse.ArgumentParser(
        description='Web Image Crawler')
    parser.add_argument('--path', default='C:/Users/rlatj/Desktop/Crawled_Images/', help='Directory to save images')
    parser.add_argument('--webdriver',default= "C://chromedriver.exe", help='Chromedriver path')
    parser.add_argument('--mp3',default='./sound.mp3',help='mp3 path')
    parser.add_argument('--filter_size',type=int, help='Minimum image size to keep')
    args = parser.parse_args()
    return args


def main():
    args = parse_args()

    class Crawler:
        def __init__(self):
            
            #  ì´ë¯¸ì§€ë“¤ì´ ì €ì¥ë  ê²½ë¡œ ë° í´ë” ì´ë¦„
            self.path = args.path
            
            # ê²€ìƒ‰ì–´ ì…ë ¥ ë° ì¤‘ë³µ ê²€ì‚¬
            self.query = input('ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥ : ')
            
            # ì›¹ ë¸Œë¼ìš°ì €ì˜ ê°œë°œì ëª¨ë“œ(F12)ë¥¼ ì—´ì–´ consoleì— navigator.userAgentë¼ê³  ì…ë ¥ í›„ ì¶œë ¥ë˜ëŠ” ê°’ì„ ë³µì‚¬
            user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'
            opts = Options()
            opts.add_argument(f"user-agent={user_agent}")
            opts.add_argument('headless')  # ì°½ ë„ìš¸ì§€ ë§ì§€ 
            opts.add_argument('window-size=1920x1080')
            opts.add_argument('disable-gpu')
            opts.add_argument('ignore-certificate-errors')
            
            # ë“œë¼ì´ë²„ ìƒì„±
            self.driver = webdriver.Chrome(args.webdriver, options=opts)
            
            # clickAndRetrieve() ê³¼ì •ì—ì„œ urlretrieveì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦´ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ íƒ€ì„ ì•„ì›ƒ ì§€ì •
            socket.setdefaulttimeout(30)
            
            # í¬ë¡¤ë§í•œ ì´ë¯¸ì§€ ìˆ˜ 
            self.crawled_count = 0
            
            # mp3 íŒŒì¼ ê²½ë¡œ
            self.mp3 = args.mp3

    #####################################################################################################################
        def scroll_down(self):
            scroll_count = 0
            
            print("-- ìŠ¤í¬ë¡¤ ë‹¤ìš´ ì‹œì‘ --")
            
            # ìŠ¤í¬ë¡¤ ìœ„ì¹˜ê°’ ì–»ê³  last_heightì— ì €ì¥
            last_height = self.driver.execute_script("return document.body.scrollHeight")
        
            # 'ê²°ê³¼ ë”ë³´ê¸°' ë²„íŠ¼ì„ í´ë¦­í–ˆëŠ” ì§€ ìœ ë¬´
            after_click = False
            
            while True:
                print(f"-- ìŠ¤í¬ë¡¤ íšŸìˆ˜ : {scroll_count} --")
                
                # ìŠ¤í¬ë¡¤ ë‹¤ìš´
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                scroll_count += 1
                time.sleep(1.5)
                
                # ìŠ¤í¬ë¡¤ ìœ„ì¹˜ê°’ ì–»ê³  new_height ì— ì €ì¥
                new_height = self.driver.execute_script("return document.body.scrollHeight")
                
                # ìŠ¤í¬ë¡¤ì´ ìµœí•˜ë‹¨ì´ë©°
                if last_height == new_height:
                    
                    # 'ê²°ê³¼ ë”ë³´ê¸°' ë²„íŠ¼ì„ í´ë¦­í•œ ì ì´ ìˆëŠ” ê²½ìš°
                    if after_click is True:
                        print(" -- ìŠ¤í¬ë¡¤ ë‹¤ìš´ ì¢…ë£Œ --")
                        break
                    
                    # 'ê²°ê³¼ ë”ë³´ê¸°' ë²„íŠ¼ì„ í´ë¦­í•œ ì ì´ ì—†ëŠ” ê²½ìš°
                    elif after_click is False:
                        if self.driver.find_element_by_css_selector(".mye4qd").is_displayed():
                            self.driver.find_element_by_css_selector(".mye4qd").click()
                            print("-- 'ê²°ê³¼ ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ --")
                            after_click = True
                        elif NoSuchElementException:
                            print(' -- NoSuchElementException --')
                            print(' -- ìŠ¤í¬ë¡¤ ë‹¤ìš´ ì¢…ë£Œ --')
                            break
                last_height = new_height
                
    #####################################################################################################################
        
        def click_and_retrieve(self,index, img, img_list_length):
            
            try:
                ActionChains(self.driver).click(img).perform()
                time.sleep(1.5)
                self.driver.implicitly_wait(3)
                imgurl = self.driver.find_element_by_xpath('/html/body/div[2]/c-wiz/div[3]/div[2]/div[3]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[3]/div/a/img').get_attribute("src")
                
                # í™•ì¥ì 
                if re.search(r"jpeg|png",imgurl):
                    ext = re.search(r"jpeg|png", imgurl).group()
                else:
                    ext = 'jpg'
                
                # ì €ì¥ë  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
                dst = os.path.join(self.path,self.query,f"{self.query}_{self.crawled_count+1}.{ext}")
                self.crawled_count += 1
                
                urlretrieve(imgurl, f"{dst}")
                self.driver.implicitly_wait(3)
                print(f"{index + 1} / {img_list_length} ë²ˆì§¸ ì‚¬ì§„ ì €ì¥ {ext}")
                
            except HTTPError:
                print("ã…¡ HTTPError & íŒ¨ìŠ¤ ã…¡")
                pass

    #####################################################################################################################
            
        def crawling(self):
            print('-- í¬ë¡¤ë§ ì‹œì‘ --')
            
            self.driver.get("https://www.google.co.kr/imghp?hl=ko&authuser=0&ogbl")
            time.sleep(2)
            self.driver.find_element_by_css_selector("input.gLFyf").send_keys(self.query) #send keyword
            self.driver.find_element_by_css_selector("input.gLFyf").send_keys(Keys.RETURN)##send Keys.RETURN
            
            self.scroll_down()
            
            # class_nameì— ê³µë°±ì´ ìˆëŠ” ê²½ìš° ì—¬ëŸ¬ í´ë˜ìŠ¤ê°€ ìˆëŠ” ê²ƒì´ë¯€ë¡œ ì•„ë˜ì™€ ê°™ì´ css_selectorë¡œ ì°¾ìŒ
            img_list = self.driver.find_elements_by_css_selector("img.rg_i.Q4LuWd") # ì¸ë„¤ì¼
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            directory_path = os.path.join(self.path, self.query)
            if not os.path.exists(directory_path):
                os.makedirs(directory_path)
                print(f'{directory_path} í´ë” ìƒì„±')
            else : print(f"{directory_path} Directory Already Exists")
            
            for index, img in enumerate(img_list):
                try:
                    self.click_and_retrieve(index, img, len(img_list))

                except ElementClickInterceptedException:
                    print("ã…¡ ElementClickInterceptedException ã…¡")
                    self.driver.execute_script("window.scrollTo(0, window.scrollY + 100)")
                    print("ã…¡ 100ë§Œí¼ ìŠ¤í¬ë¡¤ ë‹¤ìš´ ë° 3ì´ˆ ìŠ¬ë¦½ ã…¡")
    #                 img.click()
                    ActionChains(self.driver).click(img).perform()
                    time.sleep(3)
                    self.click_and_retrieve(index, img, len(img_list))

                except NoSuchElementException:
                    print("ã…¡ NoSuchElementException ã…¡")
                    self.driver.execute_script("window.scrollTo(0, window.scrollY + 100)")
                    print("ã…¡ 100ë§Œí¼ ìŠ¤í¬ë¡¤ ë‹¤ìš´ ë° 4ì´ˆ ìŠ¬ë¦½ ã…¡")
                    time.sleep(4)
    #                 img.click()
                    ActionChains(self.driver).click(img).perform()
                    self.click_and_retrieve(index, img, len(img_list))

                except ConnectionResetError:
                    print("ã…¡ ConnectionResetError & íŒ¨ìŠ¤ ã…¡")
                    pass

                except URLError:
                    print("ã…¡ URLError & íŒ¨ìŠ¤ ã…¡")
                    pass

                except socket.timeout:
                    print("ã…¡ socket.timeout & íŒ¨ìŠ¤ ã…¡")
                    pass

                except socket.gaierror:
                    print("ã…¡ socket.gaierror & íŒ¨ìŠ¤ ã…¡")
                    pass

                except ElementNotInteractableException:
                    print("ã…¡ ElementNotInteractableException ã…¡")
                    break

            try:
                print("ã…¡ í¬ë¡¤ë§ ì¢…ë£Œ (ì„±ê³µë¥ : %.2f%%) ã…¡" % (self.crawled_count / len(img_list) * 100.0))

            except ZeroDivisionError:
                print("ã…¡ img_list ê°€ ë¹„ì–´ìˆìŒ ã…¡")

            self.driver.quit()

    #####################################################################################################################

        def filtering(self, width_threshold, height_threshold):
            print("ã…¡ í•„í„°ë§ ì‹œì‘ ã…¡")
            filtered_count = 0
            dir_name = os.path.join(self.path, self.query)
            
            for index, file_name in enumerate(os.listdir(dir_name)):
                try:
                    file_path = os.path.join(dir_name, file_name)
                    ext = file_name.split('.')[-1]
                    img = Image.open(file_path)

                    # ì´ë¯¸ì§€ í•´ìƒë„ì˜ ê°€ë¡œì™€ ì„¸ë¡œê°€ ëª¨ë‘ 800ì´í•˜ì¸ ê²½ìš°
                    if (img.width < width_threshold and img.height < height_threshold):
                        img.close()
                        os.remove(file_path)
                        print(f"{index} ë²ˆì§¸ ì‚¬ì§„ ì‚­ì œ -->  width : {img.width} height : {img.height}")
                        filtered_count += 1

                # ì´ë¯¸ì§€ íŒŒì¼ì´ ê¹¨ì ¸ìˆëŠ” ê²½ìš°
                except OSError:
                    os.remove(file_path)
                    filtered_count += 1

            print(f"ã…¡ í•„í„°ë§ ì¢…ë£Œ (ì´ ê°¯ìˆ˜: {self.crawled_count - filtered_count}) ã…¡")
                    
    #####################################################################################################################      
        def change_extension(self):
            print("ã…¡ í•„í„°ë§ ì‹œì‘ ã…¡")
            changed_count = 0
            dir_name = os.path.join(self.path, self.query)
            
            for index, file_name in enumerate(os.listdir(dir_name)):
                ext = file_name.split('.')[-1]
                img_name = file_name.split('.')[0]
                if ext != 'jpg':
                    os.rename(os.path.join(dir_name,file_name), os.path.join(dir_name,img_name+'.jpg'))
                    print(f"{index} ë²ˆì§¸ ì‚¬ì§„ í™•ì¥ì ë³€ê²½ -->  before : {ext} after : jpg")
                    changed_count+=1
                else: pass
            
            print(f"ã…¡ í™•ì¥ì ë³€í™˜ ì¢…ë£Œ (ì´ ë³€í™˜ ê°¯ìˆ˜: {changed_count}) ã…¡")

    #####################################################################################################################
        def checking(self):
            # ì…ë ¥ ë°›ì€ ê²€ìƒ‰ì–´ê°€ ì´ë¦„ì¸ í´ë”ê°€ ì¡´ì¬í•˜ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨
            for dir_name in os.listdir(self.query):
                file_list = os.listdir(os.path.join(self.query, dir_name))
                if self.query in file_list:
                    print(f"ã…¡ ì¤‘ë³µëœ ê²€ìƒ‰ì–´: ({dir_name}) ã…¡")
                    return True
                
        def playing_mp3(self):
            mixer.init()
            mixer.music.load(self.mp3)
            mixer.music.play()
            while mixer.music.get_busy():
                pass
            print(f"ã…¡ ê²€ìƒ‰ì–´: {self.query} ã…¡")

#####################################################################################################################
    crawler = Crawler()
    crawler.crawling()
    crawler.filtering(args.filter_size,args.filter_size)
    crawler.change_extension()
    crawler.playing_mp3()

if __name__ == '__main__':
    main()
