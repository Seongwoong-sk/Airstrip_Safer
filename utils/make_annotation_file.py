
# ğŸ‘‰ Annotation ìš©ë„ë¡œ ì“°ì¼ Meta File (.txt) ìƒì„±í•˜ëŠ” íŒŒì´ì¬ íŒŒì¼
# ğŸ‘‰ Train & Val & Testë¡œ ë¶„í• ë¼ìˆì§€ ì•Šì€ ë°ì´í„°(ì´ë¯¸ì§€)ì˜ íŒŒì¼ëª…ì„ ì¶”ì¶œí•´ì„œ íŒŒì¼ëª…ì„ ë‹´ì€ train & test txtíŒŒì¼ í˜•ì„±

# --> Split dataset into Train & Test   (Split dataset into Train & Val & TestëŠ” ./extract_split_move.pyì— ìœ„ì¹˜)
# --> ë°ì´í„°ì…‹ ìƒì„± ì‹œ ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ê°€ì ¸ì™€ì„œ ì´ë¯¸ì§€ íŒŒì¼ì— ë§¤ì¹­ë˜ëŠ” json íŒŒì¼ë¡œ label ì‘ì—…


'''
< Structure Example >
â”œâ”€â”€ Root folder (name : airplane_custom)
â”‚   â”œâ”€â”€ Dataset folder (name : 100_data)
â”‚         â”œâ”€â”€ images (folder name : 100_images)
â”‚         â”œâ”€â”€ labels (folder name : 100_labels)
â”‚         â”œâ”€â”€ train.txt
â”‚         â”œâ”€â”€ val.txt
â”‚         â”œâ”€â”€ (text.txt)
'''



###################################### ğŸ‘‰ Import Libraries ğŸ‘ˆ ##########################################

# #Install mmcv if not installed
# print(f"âœ¨[Info Msg] MMCV Install Start \n")
# os.system('pip install -qq mmcv-full==1.6.0 -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html')
# print(f"âœ¨[Info Msg] MMCV Install Complete ğŸ› ï¸ \n\n")


import os
import mmcv # mmcv ì„¤ì¹˜
import argparse
import pandas as pd
from glob import glob
from tqdm import tqdm


###################################### ğŸ‘‰ Hyperparameters ğŸ‘ˆ ##########################################
def parse_args():
    parser = argparse.ArgumentParser(
        description='Extract_Split_Move')
    parser.add_argument('--root_dir', help='Path : root_dir/dataset_dir/images or labels.')
    parser.add_argument('--dataset_dir', help='Name of dataset folder.') # 100_data
    parser.add_argument('--test_ratio', type=float, default=0.2, 
                        help='Ratio of test data to generate. Train : 0.8 / Test : 0.2')
    parser.add_argument('--tr_anno_name', help='Name of Train Annotation file.')
    parser.add_argument('--val_anno_name', help='Name of Valid Annotation file.')
    parser.add_argument('--test_anno_name', help='Name of Test Annotation file.')   

    args = parser.parse_args()
    # if 'LOCAL_RANK' not in os.environ:
    #     os.environ['LOCAL_RANK'] = str(args.local_rank)

    return args


def main():

    args = parse_args()

    os.chdir(f'{args.root_dir}')
    target_path = f'{args.root_dir}/{args.dataset_dir}/'
    tgt_img_path = os.path.join(target_path, '100_images')
    tgt_label_path = os.path.join(target_path, '100_labels')


    print(f'\nâœ¨[Info msg] Loading total images and labels')
    img_100_list = sorted(tqdm(glob(os.path.join(tgt_img_path,'*'))))
    label_100_list = sorted(tqdm(glob(os.path.join(tgt_label_path,'*'))))
    print(f'total imgs num : {len(img_100_list)}')
    print(f'total labels num : {len(label_100_list)}\n')


    ###################################### ğŸ‘‰ Extract Filename to make Annotation file ğŸ‘ˆ##########################################
    print(f'\nâœ¨[Info msg] Extract filenames out of imgs & labels list to make Annotation file')
    def name_parsing(file_list):

        name = []

        for i in tqdm(range(len(file_list))):
            file_list[i] = file_list[i].split('/')[-1].split('.')[0]
            name.append(file_list[i])

        return name

    imgs = name_parsing(img_100_list)
    labels = name_parsing(label_100_list)

    print(f'\nlength of imgs: {len(imgs)}')
    print(f'length of labels : {len(labels)}\n')



    ############################################### ğŸ‘‰ Data Split ğŸ‘ˆ##########################################

    # split the 100_data into two groups
    # trian 0.8, test 0.2

    # sklearn íŒ¨í‚¤ì§€ì—ì„œ ì œê³µí•˜ëŠ” ShuffleSplitê³¼ ë°ì´í„°ì…‹ì„ ë¶„í• 
    # shufflesplit í•¨ìˆ˜ëŠ” ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ë¥¼ ë¬´ì‘ìœ„ë¡œ ì‚¬ì „ì— ì„¤ì •í•œ ë¹„ìœ¨ë¡œ ë¶„í• 
    # ì¦‰, 4:1 ë¡œ ë¶„í• í•˜ê³  ì‹¶ì€ ê²½ìš°ì— ë¬´ì‘ìœ„ ì¸ë±ìŠ¤ë¡œ 4:1 ë¹„ìœ¨ë¡œ ë¶„í• 

    print(f'\nâœ¨[Info msg] Split data into Train & Test.. Ratio : {float(1-args.test_ratio)} & {args.test_ratio} ')

    from sklearn.model_selection import ShuffleSplit

    train_idx = []
    test_idx = []

    sss = ShuffleSplit(n_splits=1, test_size=args.test_ratio, random_state=100)
    indices = range(len(imgs)) # ì´ë¯¸ì§€ì˜ ì´ ê°œìˆ˜ë¥¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜

    # ê° ì´ë¯¸ì§€ë“¤ì˜ íŒŒì¼ëª…ì´ ë¦¬ìŠ¤íŠ¸ì˜ ì¸ë±ìŠ¤ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ë¥¼ í™œìš©í•´ì„œ train & test ë¶„í• 
    for train_index, test_index in sss.split(indices):  
        train_idx.append(train_index)
        test_idx.append(test_index)
    
    '''
    12000
    ----------
    3000 

    train_idx
    -->
    [array([ 6859, 10995,  4306, ..., 14147,  6936,  5640])]
    '''

    ################### ğŸ‘‰ Images Split #######################
    ## images

    # ShuffleSplitì€ arrayë¡œ ë°˜í™˜ë˜ë¯€ë¡œ listë¡œ ë³€í™˜
    tr_idx = train_idx[0].tolist()
    test_idx = test_idx[0].tolist()

    print(f'length of tr_idx :  {len(tr_idx)}')
    print(f'length of test_idx :  {len(test_idx)}\n')


    tr_imgs_list = []
    test_imgs_list = []


    for i in tr_idx :
        tr_img = imgs[i]
        tr_imgs_list.append(tr_img)


    for i in test_idx:
        test_img = imgs[i]
        test_imgs_list.append(test_img)
        
    print(f'Quantity of Train data :  {len(tr_imgs_list)}')
    print(f'Quantity of Test data :  {len(test_imgs_list)}\n')



    ################### ğŸ‘‰ Labels Split #######################
    ## labels

    tr_labels_list = []
    test_labels_list = []

    for i in tr_idx :
        tr_label = labels[i]
        tr_labels_list.append(tr_label)


    for i in test_idx :
        test_label = labels[i]
        test_labels_list.append(test_label)


    print(f'Quantity of Train label :  {len(tr_labels_list)}')
    print(f'Quantity of Test label :  {len(test_labels_list)}\n')


    print('\nâœ¨[Info msg] Check whether they are matched')
    print(f'train : {tr_imgs_list == tr_labels_list}')
    print(f'test : {test_imgs_list == test_labels_list}\n')

    ############################################### ğŸ‘‰ ann_file (meta_file) generation ğŸ‘ˆ##########################################
    ## Meta File : txt íŒŒì¼ ìƒì„± (Annotationì— ì“¸ ê²ƒ)

    print('\nâœ¨[Info msg] Start generating annotation file (Meta File) for Middle Format \n')
    # listì— ë‹´ê²¨ ìˆëŠ” filenameì„ í™œìš©í•˜ì—¬ pd.Dataframe ìƒì„±
    tr_df = pd.DataFrame({'tr_filename' : tr_imgs_list})
    test_df = pd.DataFrame({'test_filename': test_imgs_list, 'test_labels_name' : test_labels_list})


    # # ê¸°ì¡´ ì¸ë±ìŠ¤(annotation íŒŒì¼) ì‚­ì œ 
    # # Cross Validation ì—­í• 
    # os.system('rm ./100_data/train.txt')
    # os.system('rm ./100_data/val.txt')


    # Annotation íŒŒì¼ìš© txt íŒŒì¼ ìƒì„±
    # args.root_dir / args.dataset_dir / args.tr or val or test
    tr_df['tr_filename'].to_csv(f'{args.root_dir}/{args.dataset_dir}/{args.tr_anno_name}', index=False, header=False)
    test_df['test_filename'].to_csv(f'{args.root_dir}/{args.dataset_dir}/{args.test_anno_name}', index=False, header=False)
    print('âœ¨[Info msg] Generating annotation file (Meta File) Complete')
    print(f'âœ¨[Info msg] Saving ... --> {args.root_dir}/{args.dataset_dir}/{args.tr_anno_name}')
    print(f'âœ¨[Info msg] Saving ... --> {args.root_dir}/{args.dataset_dir}/{args.test_anno_name} \n')


    # txt ë‚´ì— ìˆëŠ” ì¸ìë“¤ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë¶ˆëŸ¬ì˜´
    print('âœ¨[Info msg] Check filenames in the annotation file\n')
    image_tlist = mmcv.list_from_file(f'{args.root_dir}/{args.dataset_dir}/{args.tr_anno_name}')
    image_test_list = mmcv.list_from_file(f'{args.root_dir}/{args.dataset_dir}/{args.test_anno_name}')


    print(f'Length of total Train_imgs names : {len(image_tlist[:])}')
    print(f'Train 5 imgs names : \n {image_tlist[:5]}\n')
    print(f'Length of total Test_imgs names : {len(image_test_list[:])}')
    print(f'Test 5 imgs names : \n {image_test_list[:5]}') 


if __name__ =='__main__':
    main()
